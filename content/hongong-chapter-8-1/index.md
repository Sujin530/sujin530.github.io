---
emoji: 📝
title: 합성곱 신경망
date: '2022-02-06 14:40:00'
author: Sujin
tags: 혼공머신 머신러닝 딥러닝 합성곱신경망
categories: 노트
---

## 학습 목표
* 이미지 분류 문제에 뛰어난 성능을 발휘하는 합성곱 신경망의 개념과 구성 요소에 대해 배우기
* 케라스 API로 합성곱 신경망을 만들어 패션 MNIST 데이터에서 성능을 평가해보기
* 합성곱 층의 필터와 활성화 출력을 시각화하여 합성곱 신경망이 학습한 내용을 고찰해보기


### 합성곱 신경망(CNN, Convolutional Neural Network)
* 이미지 처리에 탁월한 성능을 보이는 신경망
* 합성곱층(Convolution Layer)과 풀링층(Pooling Layer)로 구성됨
<br/>
![CNN](https://user-images.githubusercontent.com/67195038/152689093-be344fc3-a6ff-493f-b52b-958f65713c31.jpeg)
<br/>
* 일반적으로 1개 이상의 합성곱 층을 쓴 인공 신경망을 의미


### 왜 합성곱 신경망을 사용하나요?
손글씨 이미지를 예로 들어 정리해보겠습니다. 
![conv0](https://user-images.githubusercontent.com/67195038/152689233-93a38241-f14d-4642-8c78-5a0cf37b55f2.png)

위 이미지 모두 알파벳 Y라는 것은 사람이라면 손쉽게 판단이 가능합니다. 하지만 기계가 보기에는 각 픽셀마다 가진 값이 대부분 상이하므로, 다른 값을 가진 입력입니다. 
**다층 퍼셉트론**은 몇 가지 픽셀만 값이 달라져도 민감하게 예측에 영향을 받는다는 단점이 있습니다.


위 손글씨를 다층 퍼셉트론으로 분류한다고 하면, 이미지를 1차원 텐서인 벡터로 변환하고 다층 퍼셉트론 입력층으로 사용해야 합니다. 

![conv1](https://user-images.githubusercontent.com/67195038/152689235-481765e7-8bc8-4854-bb95-0349d71ca170.png)

1차원으로 변환된 결과는 살마이 보기에도 이게 원래 어떤 이미지였는지 알기 어렵고, 기계도 마찬가지입니다. 
알아보기 어려운 이유는, 변환 전에 가지고 있던 **공간적인 구조(Spatial Structure) 정보가 유실된 상태**이기 때문입니다. 
공간적인 구조 정보라는 것은 거리가 가까운 어떤 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리 값이 비슷한지 등을 포함하고 있는 정보입니다. 결국 이미지의 공간적인 구조 정보를 보존하면서 학습하기 위해 **합성곱 신경망**을 사용합니다.

### 합성곱 연산
* 합성곱층은 합성곱 연산을 통해서 **이미지의 특징을 추출**하는 역할을 합니다.
* 커널(Kernel) 또는 필터(Filter)라는 $ n \times m 크기의 행렬로 높이(height)X너비(width) 크기의 이미지를 훑으면서 $ n \times m 

1. 첫번째 스텝
![conv4](https://user-images.githubusercontent.com/67195038/152689585-1a4e9409-28f0-4bfd-af83-35829e4dd954.png)

2. 두번째 스텝
![conv5](https://user-images.githubusercontent.com/67195038/152689587-b0208f4b-11f2-4a84-8191-933a67ea75da.png)

3. 세번째 스텝
![conv6](https://user-images.githubusercontent.com/67195038/152689588-35265e92-1f1d-40fd-9bd6-0807305ff194.png)

4. 네번째 스텝
![conv7](https://user-images.githubusercontent.com/67195038/152689589-632909ec-cb79-489e-b966-37cd0b73edbf.png)

#### 위의 연산을 총 9번의 스텝까지 마쳤다고 가정했을 때, 최종 결과 = 특성 맵(Feature Map)
![conv8](https://user-images.githubusercontent.com/67195038/152689590-a5647a3b-a5ec-426b-92da-672a625851a6.png)

### 특성 맵 
* 입력으로부터 커널을 사용하여 합성곱 연산을 통해 나온 결과

<img width="634" alt="8-1 (2)" src="https://user-images.githubusercontent.com/67195038/152688263-4de396db-d356-44b8-b228-1fdc3a34dce4.png">

* 합성곱층을 여러 겹 쌓을수록 고수준의 특징을 감지하는 특성 맵을 만들 수 잇습니다.
* 초반의 합성고븡에서 모서리나 질감 같은 저수준의 특징을 잡아내고 이후의 층으로 갈수록 이런 저수준의 특징을 이용해 눈, 코, 입 같은 고수준의 특징을 감지합니다. 
* 최종적으로 딥러닝 모델은 고수준의 특징을 종합하여 이미지에 대한 결론을 도출합니다.

### 합성곱 신경망의 특징
* 합성곱 연산의 결과로 얻은 특성 맵은 입력보다 크기가 작아집니다.
* 합성곱 층을 여러개 쌓았다면 최종적으로 얻은 특성 맵은 초기 입력보다 매우 작아진 상태가 됩니다.
* 합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지되도록 하고 싶다면 패딩(Padding)을 사용할 수 있음


### 합성곱 신경망의 특징
* 합성곱은 일부에 가중치를 곱합니다. 
* 합성곱 층의 뉴런에 있는 가중치 개수는 정하기 나름입니다. 가중치 개수 = 하이퍼파라미터
* 뉴런 = 필터 = 커널
* 합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것!

### 필터
* 뉴런, 커널과 같은 개념
* 밀집층에서 여러 개의 뉴런을 사용하듯이 합성곱 층에서도 여러 개의 필터를 사용함
* 밀집층에 있는 뉴런의 가중치가 모두 다르듯이 합성곱 층에 있는 필터의 가중치(커널)도 모두 다름

### 합성곱 신경망이 이미지 처리 분야에서 뛰어난 성능을 발휘하는 이유
  * 입력보다 훨씬 작은 크기의 커널을 사용하고 입력 위를 이동하면서 2차원 특성 맵을 만듬
  * 2차원 구조를 그대로 사용하기 때문에 

### 케라스 합성곱 층
* 케라스의 층은 모두 keras.layers 패키지 아래 클래스로 구현되어 있음. 합성곱 층도 마찬가지!
* 합성곱은 Conv2D 클래스로 제공됨

### Conv2D 클래스
* 첫 번째 매개변수 = 필터
* kernel_size 매개변수는 필터에 사용할 커널의 크기를 지정
* 필터의 개수와 커널의 크기는 반드시 지정해야 하는 매개변수
* 커널의 크기는 하이퍼 파라미터. 여러 가지 값을 시도해봐야 하지만, 보통은 (3, 3)이나 (5, 5) 크기가 권장됨
* 활성화 함수 지정


<img width="460" alt="8-1 (1)" src="https://user-images.githubusercontent.com/67195038/152688254-8d6f7ab7-1cd3-47a0-9b1c-82f3d09d85c0.png">
## 패딩과 스트라이드
### 패딩(Padding)
* (합성곱 연산을 하기 전에) 입력의 가장자리에 지정된 개수의 폭만큼 행과 열을 추가해주는 것
* 실제 입력값이 아니기 때문에 패딩은 0으로 채움
* (4, 4) 크기의 입력에 0을 1개 패딩하면 다음과 같은 (6, 6) 크기의 입력이 됨

<img width="827" alt="스크린샷 2022-02-07 오전 1 23 27" src="https://user-images.githubusercontent.com/67195038/152690569-28658962-2003-4475-833b-7e36874f4bbb.png">

### 세임 패딩(Same Padding)
* 입력과 특성 맵의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것
* 합성곱 신경망에서는 세임 패딩이 많이 사용됨
* 즉, 입력과 특성 맵의 크기를 동일하게 만드는 경우가 많음

### 밸리드 패딩(Valid Padding)
* 패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 것
* 밸리드 패딩은 특성 맵의 크기가 줄어들 수 밖에 없음

### 합성곱에서 패딩을 즐겨 사용하는 이유
* 적절한 패딩은 이미지의 주변에 있는 정보를 잃어버리지 않도록 도와줌
* 일반적인 합성곱 신경망에서는 세임 패딩이 많이 사용됨
* 케라스 Conv2D 클래스에서는 padding 매개변수로 패딩을 지정할 수 있음

### 스트라이드(Stride)
* 커널의 이동 범위. 합성곱에서 이동할 때의 크기를 지정하는 것
* 기본적인 스트라이드는 1. 한 칸씩 이동함.
* 대부분 기본값을 그대로 사용하기 때문에 strides 매개변수를 잘 사용하지 않음

## 풀링(Pooling)
* 합성곱 층에서 만든 특성 맵의 크기로 데이터의 주요한 특징은 살리면서 특성 맵의 크기를 줄이는 역할을 함
* 풀링 연산에서도 합성곱 연산과 마찬가지로 커널과 스트라이드 개념이 있음. 
* 합성곱 연산과 풀링의 차이는 학습해야 할 가중치가 없으며 연산 후에 채널 수가 변하지 않는다는 점.

### 최대 풀링(Max Pooling)
* 가장 큰 값을 고르는 것
* 최대 풀링을 제공하는 클래스는 MaxPooling2D
* 첫번째 매개변수로 풀링의 크기 지정. 대부분 풀링 크기 2.
* strides와 padding 매개변수 제공. 
* strides 기본값은 자동으로 풀링의 크기라서 따로 지정할 필요 없음
* padding의 기본 값은 valid로 패딩 하지 않음

### 평균 풀링(Average Pooling)
* 평균 풀링을 제공하는 클래스는 AveragePooling2D
* 평균 풀링보다 최대 풀링을 많이 사용. 이유는? 평균 풀링이 특성 맵에 있는 중요한 정보를 (평균하여) 희석시킬 수 있기 때문

### 풀링을 사용하는 이유
* 합성곱에서 스트라이드를 크게 하여 특성 맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문

## 합성곱 신경망의 전체 구조
### 컬러 이미지를 사용한 합성곱
* 패션 MNIST 데이터는 실제로 흑백 이미지이기 때문에 2차원 배열로 표현
* 컬러이미지는 RGB 채널로 구성되어있기 때문에 컴퓨터는 이를 3차원 배열로 표시함
* 커널 배열의 깊이는 항상 입력의 깊이와 같음

* 입력이나 필터의 차원이 몇 개인지 상관없이 항상 출력은 하나의 값이라는 점. 즉 특성 맵에 있는 한 원소가 채워짐!
* 케라스의 합성곱 층은 항상 이렇게 3차원 입력을 기대함. 패션 MNIST 데이터처럼 흑백 이미지일 경우에는 깊이 차원이 1인 3차원 배열로 변환하여 전달함

* 합성곱 신경망은 너비와 높이는 점점 줄어들고 깊이는 점점 깊어지는 것이 특징임
* 마지막에 출력층 전에 특성 맵을 모두 펼쳐서 밀집층의 입력으로 사용함


## 용어 정리
* 필터
* 커널
* 특성 맵



### 참고자료
* 혼자 공부하는 머신러닝 + 딥러닝 
* 이토록 쉬운 머신러닝 & 딥러닝 입문 with 사이킷런 + 파이토치
* 딥 러닝을 이용한 자연어 처리 입문 https://wikidocs.net/64066